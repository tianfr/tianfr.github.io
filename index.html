<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Fengrui Tian </title>
  
  <meta name="author" content="Fengrui Tian">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ˜‰</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>
                  Fengrui Tian &nbsp  
                  <font face="KaiTi" size="6">ç”°ä¸°ç‘ž</font>
                </name>
              </p>
              <p>I'm an incoming 2024 Fall Ph.D. student at <a href="https://www.grasp.upenn.edu/">GRASP Lab</a>, <a href="https://www.upenn.edu/">University of Pennsylvania</a>, advised by <a href="http://vision.jhu.edu/rvidal.html">Prof. RenÃ© Vidal</a>. My major research direction is 3D vision.</p>
                
              <p>For now, I am a research intern at <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, 
              where I'm very fortunate to work with <a href="https://duanyueqi.github.io/">Prof. Yueqi Duan</a> and focus on novel view synthesis. 
              </p>
              <p>Before that, I received my M.Eng. degree from the the <a href="http://iair.xjtu.edu.cn/">College of Artificial Intelligence</a> of <a href="http://www.xjtu.edu.cn/">Xi'an Jiaotong University</a>, under the supervision of <a href="https://gr.xjtu.edu.cn/en/web/dushaoyi/home">Prof. Shaoyi Du</a>, with the general ranking 1/107+. 
                During my master's study, I was a research intern at <a href="https://ccvl.jhu.edu/">CCVL group</a> of <a href="https://www.jhu.edu/">Johns Hopkins University</a>, advised by <a href="https://www.cs.jhu.edu/~ayuille/index.html">Prof. Alan Yuille</a> and <a href="https://angtianwang.github.io/">Angtian Wang</a>. I was also an intern at <a href="https://www.shlab.org.cn/">Shanghai Artificial Intelligence Laboratory</a>, <a href="https://www.sensetime.com/">Sensetime Research</a> and
                <a href="https://www.megvii.com/">Megvii Research</a>. I received my B.Eng. degree from  the <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">School of Software Engineering</a> of <a href="http://www.xjtu.edu.cn/">Xi'an Jiaotong University</a>, supervised by <a href="https://gr.xjtu.edu.cn/en/web/zhiqiangtian/home">Prof. Zhiqiang Tian</a>, with the honor of Best Undergraduate Thesis (rank 1/110+). 
              </p>
              <p>
                I support <a href="http://slow-science.org/">Slow Science</a> but it is really hard for me to practice it now.
              </p>
              <!-- <p>  I'm looking for Ph.D. positions in computer vision in Fall 2024. If you are interested in my background and have some available positions, please let me know. 
              </p> -->
              <p style="text-align:center">
                <a href="mailto:tianfr1999@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=jQ5a6axA_XEC">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/tianfr/">Github</a> &nbsp/&nbsp
                <!-- <a href="https://orcid.org/0000-0002-9577-5276">ORCID</a> &nbsp/&nbsp -->
                <a href="data/CV_Fengrui_Tian_latest.pdf">Full CV (updated to 2023.1.19)</a>

              </p>
            </td>
            <!-- <td style="padding:2.5%;width:25%;max-width:25%">
              <a href="images/Fengrui_Tian_avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Fengrui_Tian_avatar.jpg" class="hoverZoomLink"></a>
            </td> -->
            <td style="padding:2.5%;width:35%;max-width:35%">
              <a href="images/American_style/still.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/American_style/still.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        <!-- </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table> -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <br>    <br> 
          <tr>
            <td>
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
                    <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/pose_estimator_wo_pose_overview.png" alt="prl" width="200" height="95">
            </td>
            <td width="75%" valign="middle">
              <a href="">
                <papertitle>Learning a Category-level Pose Estimator without Pose Annotations</papertitle>
              </a>
              <br>
              <strong>Fengrui Tian</strong>,
              <a href="https://www.cs.jhu.edu/~yyliu/">Yaoyao Liu</a>,
              <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>,
              <a href="https://gvrl.mpi-inf.mpg.de/">Adam Kortylewski</a>,
              <a href="https://duanyueqi.github.io/">Yueqi Duan</a>,
              <a href="https://gr.xjtu.edu.cn/en/web/dushaoyi/home">Shaoyi Du</a>,
              <a href="https://scholar.google.com/citations?user=YR7re-cAAAAJ&hl=zh-CN">Angtian Wang</a>
              <br>
              <em>Under review</em>, 2024
              <br>
               <a href="https://arxiv.org/abs/2404.05626">arxiv</a>  &nbsp<!--/&nbsp  -->
              <!-- <a href="data/iclr24SemanticFlow.bib">bibtex</a> -->
              <p></p>
              <p>
              We propose to leverage the power of diffusion model to train a category-level pose estimator without requiring any pose annotations. 
              </p>
            </td>
          </tr>

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/semantic_flow_teaser.png" alt="prl" width="200" height="95">
            </td>
            <td width="75%" valign="middle">
              <a href="">
                <papertitle>Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos</papertitle>
              </a>
              <br>
              <strong>Fengrui Tian</strong>,
              <a href="https://duanyueqi.github.io/">Yueqi Duan</a>,
              <a href="https://scholar.google.com/citations?user=YR7re-cAAAAJ&hl=zh-CN">Angtian Wang</a>,
              <a href="https://ventusff.github.io/">Jianfei Guo</a>,
              <a href="https://gr.xjtu.edu.cn/en/web/dushaoyi/home">Shaoyi Du</a>
              <br>
              <em>ICLR</em>, 2024
              <br>
              <a href="https://openreview.net/forum?id=A2mRcRyGdl">open review</a>  &nbsp/&nbsp 
              <a href="https://arxiv.org/abs/2404.05163">arxiv</a>  &nbsp/&nbsp 
              <a href="https://github.com/tianfr/Semantic-Flow">code</a>  &nbsp/&nbsp 
              <a href="data/iclr24SemanticFlow.bib">bibtex</a>
              <p></p>
              <p>
              We propose Semantic Flow that builds semantic fields of dynamic scenes from monocular videos. 
              </p>
            </td>
          </tr>

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mononerf_teaser.png" alt="prl" width="200" height="95">
            </td>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/tcvm_overview.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td> -->
            <!-- <td style="padding:20px;width:75%;vertical-align:middle"> -->
            <td width="75%" valign="middle">
              <a href="paper/Tian_MonoNeRF_arxiv.pdf">
                <papertitle>MonoNeRF: Learning a Generalizable Dynamic Radiance Field from Monocular Videos</papertitle>
              </a>
              <br>
              <strong>Fengrui Tian</strong>,
              <a href="https://gr.xjtu.edu.cn/en/web/dushaoyi/home">Shaoyi Du</a>,
              <a href="https://duanyueqi.github.io/">Yueqi Duan</a>
              <br>
              <em>ICCV</em>, 2023 
              <!-- &nbsp <font color="red">(Oral Presentation, <strong>Best Paper Award Honorable Mention</strong>)</font> -->
              <br>
              <a href="paper/Tian_MonoNeRF_arxiv.pdf">pdf</a> &nbsp/&nbsp 
              <a href="https://arxiv.org/abs/2212.13056">arxiv</a> &nbsp/&nbsp
              <a href="data/iccv23_MonoNeRF_poster.pdf">poster</a> &nbsp/&nbsp
              <a href="https://github.com/tianfr/MonoNeRF">code</a> &nbsp/&nbsp
              <a href="https://www.youtube.com/watch?v=A6O4Q3PZZ18">youtube video</a> &nbsp/&nbsp
              <a href="https://livejohnshopkins-my.sharepoint.com/:v:/g/personal/zzhou82_jh_edu/ERr1M3Ze8kFNn85fCdIOEC4BZgu8AOWavzqBSJ2ywTD67A?e=zVChTK">talk at CCVL</a> &nbsp/&nbsp
              <a href="data/iccv23MonoNeRF.bib">bibtex</a>
              <p></p>
              <p>
              We propose MonoNeRF for learning a generalizable dynamic radiance field from monocular videos. While independently using 2D local features and
              optical flows suffers from ambiguity along the ray direction, they provide complementary constraints to jointly learn 3D
              point features and scene flows.
              </p>
            </td>
          </tr>

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tcvm_overview.jpg" alt="prl" width="200" height="95">
            </td>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/tcvm_overview.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('dreamfusion_image').style.opacity = "1";
                }

                function dreamfusion_stop() {
                  document.getElementById('dreamfusion_image').style.opacity = "0";
                }
                dreamfusion_stop()
              </script>
            </td> -->
            <!-- <td style="padding:20px;width:75%;vertical-align:middle"> -->
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content/ACCV2022/html/Tian_TCVM_Temporal_Contrasting_Video_Montage_Framework_for_Self-supervised_Video_Representation_ACCV_2022_paper.html">
                <papertitle>TCVM: Temporal Contrasting Video Montage Framework for Self-supervised Video Representation Learning</papertitle>
              </a>
              <br>
              <strong>Fengrui Tian</strong>,
              Jiawei Fan,
              Xie Yu,
              <a href="https://gr.xjtu.edu.cn/en/web/dushaoyi/home">Shaoyi Du</a>,
              Meina Song,
              Yu Zhao
              <br>
              <em>ACCV</em>, 2022 &nbsp <font color="red">(Oral Presentation, <strong>Best Paper Award Honorable Mention</strong>)</font>
              <br>
              <a href="paper/Tian_TCVM_Temporal_Contrasting_Video_Montage_Framework_for_Self-supervised_Video_Representation_ACCV_2022_paper.pdf">pdf</a>  &nbsp/&nbsp
              <a href="data/accv22TCVM.bib">bibtex</a>
              <p></p>
              <p>
              We propose a framework for self-supervised video contrastive learning.
              </p>
            </td>
          </tr>
		  

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/surfacegcn.jpg" alt="prl" width="200" height="85">
            </td>
            <td width="75%" valign="middle">
              <a href="https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.16280">
                <papertitle>Surface-GCN: Learning Interaction Experience for Organ Segmentation in 3D Medical Images</papertitle>
              </a>
              <br>
              <strong>Fengrui Tian</strong>, 
              <a href="https://gr.xjtu.edu.cn/en/web/zhiqiangtian/home">Zhiqiang Tian</a>,
              Zhang Chen,
              Dong Zhang,
              <a href="https://gr.xjtu.edu.cn/en/web/dushaoyi/home">Shaoyi Du</a>
              <br>
              <em><a href="https://aapm.onlinelibrary.wiley.com/journal/24734209">Medical Physics</a></em>, 2023 &nbsp (IF: 4.071)
              <br>
              <a href="https://onlinelibrary.wiley.com/share/author/WQ4CIMTNAPDTNDRKVFJK?target=10.1002/mp.16280">paper</a>   &nbsp/&nbsp
              <a href="paper/Tian_Surface-GCN_MP_2023_preprint.pdf">pdf</a>   &nbsp/&nbsp
              <a href="paper/Tian_Surface-GCN_MP_2023_supplementary_material.pdf">supplementary material</a>   &nbsp/&nbsp
              <a href="data/mp23Surface-GCN.bib">bibtex</a>
              <p>We propose a framework for learning radiologists' experience in medical organ segmentation.</p>
            </td>
          </tr>

        </tbody></table>

        <br>  <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr style="padding:0px">
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody style="padding:20px">
          <tr >
            <td style="padding:0px 20px;width:100%;vertical-align:middle;line-height:20px;">
              <strong>Conference Reviewer</strong> 
              <li> IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR) <a href="https://cvpr2023.thecvf.com/Conferences/2023">2023</a>, <a href="https://cvpr.thecvf.com/Conferences/2024">2024</a></li> 
              <li> ACM Multimedia (ACM MM) <a href="https://2024.acmmm.org/">2024</a></li> 
              <li> Neural Information Processing Systems (NIPS) <a href="https://neurips.cc/Conferences/2024">2024 </a></li>
              <li> Chinese Conference on Pattern Recognition and Computer Vision (PRCV) <a href="http://www.prcv.cn/">2024 </a></li>
              <br>
              <strong>Journal Reviewer</strong> 
              <li > <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </a> </li> 
              <li > <a href="https://dl.acm.org/journal/tog">ACM Transactions on Graphics (ToG)</a> </li>
          </td>
            
          </tr>
        </tbody></table>
        <br>
        <br>
        <!-- <br> -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr style="padding:0px">
            <td>
              <heading>Honors</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody style="padding:20px">
          <tr >
            <td style="padding:0px 20px;width:100%;vertical-align:middle;line-height:20px;">
              <li><strong>ACCV Best Paper Award Honorable Mention (2/278)</strong>,&nbsp; 2022 </li> 
              <li>Top 15 Postgraduates Honorable Mention, Xi'an Jiaotong University <strong>(Top 0.1%)</strong>,&nbsp; 2023 </li> 
              <li>National Scholarship, Xi'an Jiaotong University <strong>(Top 0.1%)</strong>,&nbsp; 2023 </li> 
              <li>Xiaomi Special Scholarship, Xi'an Jiaotong University <strong>(Top 0.1%)</strong>,&nbsp; 2023 </li> 
              <li>Special Scholarship, Xi'an Jiaotong University (Top 10%),&nbsp; 2022 </li> 
              <li>Best Undergraduate Thesis, Xi'an Jiaotong University (rank 1/110+),&nbsp; 2021 </li>
              <li>Best Master's Thesis, Xi'an Jiaotong University (rank 1/107+),&nbsp; 2024 </li> <br>
          </td>
            
          </tr>
          
					
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr style="padding:0px">
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody style="padding:20px">
          <tr >
            <td style="padding:0px 20px;width:100%;vertical-align:middle;line-height:20px;">
              I am a <Strong>badminton player</Strong>. I played badminton at XJTU, Tsinghua University, SenseTime Corp., and JHU. 
              <br>
              Here are several awards I have won:
              <li>Quarter Final of Badminton Men's Single Contest, SenseTime Corp.,&nbsp; 2023 </li> 
              <li>Semi Final of Freshman Cup Badminton, Faculty of Electronic and Information Engineering, XJTU,&nbsp; 2022 </li> 
              Don't hesitate to <a href="mailto:tianfr1999@gmail.com">contact me</a> if you want to play badminton with me!
              <br>
              <br>
              I spent a wonderful time on the <Strong>Model United Nations</Strong> activities with my closest friends during my undergraduate study.
              I appreciate and never forget those memories.
            </td>
            
          </tr>
          
					
        </tbody></table>
        
        <table width="30%" align="right" border="0"  cellspacing="0" cellpadding="0"><tbody style="padding:0px;text-align:right"><tbody>
          <tr >
            <td style="padding:40px 0px 0px;width:100%;vertical-align:middle;line-height:0px;">
          <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=WXVqg2kYGsIY5G4MjqSGNYKVJI2nQs-7CMQylmE1UG8&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script> 
          <!-- <a href='https://clustrmaps.com/site/1bzfd'  title='Visit tracker'><img src='http//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=WXVqg2kYGsIY5G4MjqSGNYKVJI2nQs-7CMQylmE1UG8'/></a> -->
            </td>
          </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <!-- <br> -->
              <p style="text-align:right;font-size:small;">
                The website template was borrowed from the <a href="https://github.com/jonbarron/website">source code</a> and <a href="https://jonbarron.info/"> this page</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
